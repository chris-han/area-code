<img width="1074" height="120" alt="Area Code starter repo powered by Moose â€” Operational Data Warehouse with Streamlit" src="https://github.com/user-attachments/assets/a860328a-cb75-41a2-ade4-b9a0624918e0" />

# Area Code - Operational Data Warehouse Starter Application

---

> âš ï¸ **ALPHA RELEASE** - This is an early alpha version under active development. We are actively testing on different machines and adding production deployment capabilities. Use at your own risk and expect breaking changes.

Area Code ODW is a production-ready starter repository with all the necessary building blocks for building operational data warehouses with real-time data processing, analytics, and visualization capabilities.

## ğŸš€ Quick Start

### Prerequisites

- [uv](https://docs.astral.sh/uv/) CLI for Python environment management (`curl -LsSf https://astral.sh/uv/install.sh | sh`)
- `envsubst` from GNU gettext (Ubuntu: `sudo apt-get install -y gettext-base`)

Get up and running in minutes with our automated setup:

```bash
# 1. Ensure Docker Desktop is running
# 2. Seed databases with sample data

GRANT ALL PRIVILEGES ON `finops-odw`.* TO finops;
bun run odw:dev:seed
# 3. Install dependencies & start development environment
bun run odw:dev
# 4. Open the data warehouse frontend
http://localhost:8501/
```

This will:

- Install all Python dependencies and create virtual environment
- Start the data warehouse service (Moose app) on port 4200
- Start the Streamlit frontend on port 8501
- Launch Kafdrop UI for message queue monitoring on port 9999
- Open the dashboard in your browser automatically

## ğŸ› ï¸ Available Scripts

```bash
# Development
bun run odw:dev              # Start all services
bun run odw:dev:clean        # Clean all services

# Individual services
bun run --filter dw-frontend dev           # Frontend only
bun run --filter data-warehouse dev        # Data Warehouse only
bun run --filter kafdrop dev               # Kafdrop only
```

## ğŸ—ï¸ Tech Stack

| Category             | Technologies                                        |
| -------------------- | --------------------------------------------------- |
| **Frontend**         | Streamlit, Python 3.12+                            |
| **Backend**          | Moose, Python, FastAPI                             |
| **Database**         | ClickHouse (analytical), PostgreSQL (temporal)     |
| **Message Queue**    | Redpanda (Kafka-compatible)                        |
| **Workflow Engine**  | Temporal                                           |
| **Caching**          | Redis                                              |
| **Data Processing**  | Kafka Python, ClickHouse Connect                   |
| **Infrastructure**   | Docker, Docker Compose                             |
| **Build Tool**       | Python setuptools, pip                             |

## ğŸ“ Project Structure

```
area-code/
â”œâ”€â”€ odw/                      # Operational Data Warehouse
â”‚   â”œâ”€â”€ services/            # Backend services
â”‚   â”‚   â”œâ”€â”€ data-warehouse/  # Main Moose data warehouse service
â”‚   â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ apis/    # REST API endpoints for data consumption
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ blobs/   # Blob data extraction workflows
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ events/  # Events data extraction workflows
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ingest/  # Data models and stream transformations
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ logs/    # Log data extraction workflows
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ views/   # Materialized views for analytics
â”‚   â”‚   â”‚   â”œâ”€â”€ docs/        # Documentation and walkthrough guides
â”‚   â”‚   â”‚   â”œâ”€â”€ scripts/     # Service management scripts
â”‚   â”‚   â”‚   â”œâ”€â”€ moose.config.toml # Moose framework configuration
â”‚   â”‚   â”‚   â””â”€â”€ requirements.txt # Python dependencies
â”‚   â”‚   â””â”€â”€ connectors/      # External data source connectors
â”‚   â”‚       â””â”€â”€ src/
â”‚   â”‚           â”œâ”€â”€ blob_connector.py    # Blob storage data connector
â”‚   â”‚           â”œâ”€â”€ events_connector.py  # Events data connector
â”‚   â”‚           â”œâ”€â”€ logs_connector.py    # Logs data connector
â”‚   â”‚           â””â”€â”€ connector_factory.py # Connector factory pattern
â”‚   â””â”€â”€ apps/
â”‚       â””â”€â”€ dw-frontend/     # Streamlit web application
â”‚           â”œâ”€â”€ pages/       # Frontend page components
â”‚           â”œâ”€â”€ utils/       # Frontend utility functions
â”‚           â””â”€â”€ main.py      # Streamlit application entry point
```

## ğŸ”§ Services Overview

### Frontend (dw-frontend)

- Modern Streamlit web application with real-time data visualization
- Interactive dashboards for analytics and monitoring
- Real-time status monitoring and queue management
- Responsive design with custom styling and tooltips

### Data Warehouse Service

- [Moose analytical APIs + ClickHouse](https://docs.fiveonefour.com/moose/building/consumption-apis) with automatic OpenAPI/Swagger docs
- [Moose streaming Ingest Pipelines + Redpanda](https://docs.fiveonefour.com/moose/building/ingestion) for real-time data processing
- [Moose workflows + Temporal](https://docs.fiveonefour.com/moose/building/workflows) for durable long-running data synchronization
- REST API endpoints for data consumption and analytics
- Materialized views for optimized query performance

### Connectors Service

- Modular data connector system for external data sources
- Factory pattern for easy connector integration
- Support for blob storage, events, and logs data sources
- Extensible architecture for custom data connectors

### Infrastructure Services

- **Redpanda**: Kafka-compatible message queue for real-time data streaming
- **ClickHouse**: High-performance analytical database
- **Temporal**: Workflow engine for reliable data processing
- **Redis**: Caching and session management
- **Kafdrop**: Web UI for monitoring message queues

## ğŸ“Š Data Architecture

The application uses a modern data architecture:

1. **ClickHouse** (Analytical Database)
2. **Redpanda** (Message Queue)
3. **Temporal** (Workflow Engine)
4. **Redis** (Caching)

## ğŸš€ Production Deployment (Coming Soon)

> ğŸš§ **UNDER DEVELOPMENT** - Production deployment capabilities are actively being developed and tested. The current focus is on stability and compatibility across different machine configurations.

We're working on a production deployment strategy that will be available soon.

## ğŸ› Troubleshooting

> ğŸ”¬ **TESTING STATUS** - We are actively testing on various machine configurations. Currently tested on Mac M3 Pro (18GB RAM), M4 Pro, and M4 Max. We're expanding testing to more configurations.

### Common Issues

1. **Python Version**: Ensure you're using Python 3.12+ (required for Moose)
2. **Docker**: Make sure Docker Desktop is running before setup
3. **Memory Issues**: ClickHouse and Redpanda require significant memory (4GB+ recommended)
4. **Port Conflicts**: Ensure ports 4200, 8501, 9999, 18123, 19092 are available

**Tested Configurations:**

- âœ… Mac M3 Pro (18GB RAM)
- âœ… Mac M4 Pro
- âœ… Mac M4 Max
- ğŸ”„ More configurations being tested

### Reset Environment

```bash
# Navigate to data warehouse directory
cd odw/services/data-warehouse

# Clean and restart
./scripts/clean.sh

# Start services
bun run odw:dev

# shows Moose services, pipelines, and external dependencies 
 moose-cli status 
 # Run it from odw/services/data-warehouse
```

## ğŸ“š Resources

### ğŸ¦Œ **Moose Resources**

- **[ğŸš€ Moose Repository](https://github.com/514-labs/moose)** - The framework that powers this demo
- **[ğŸ“š Moose Documentation](https://docs.fiveonefour.com/moose)** - Complete guide to building with Moose
- **[ğŸ’¬ Moose Community Slack](https://join.slack.com/t/moose-community/shared_invite/zt-210000000000000000000000000000000000000000)** - Join the discussion

### ğŸ› ï¸ **Other Technologies**

- [Streamlit](https://streamlit.io/)
- [ClickHouse](https://clickhouse.com/)
- [Redpanda](https://redpanda.com/)
- [Temporal](https://temporal.io/)
- [Kafdrop](https://github.com/obsidiandynamics/kafdrop)

## ğŸ†˜ Support

> ğŸ“‹ **ALPHA FEEDBACK** - We welcome feedback and bug reports during this alpha phase. Please include your machine configuration when reporting issues.

### ğŸ¦Œ **Moose Support**

- **[ğŸ’¬ Moose Discussions](https://github.com/514-labs/moose/discussions)** - Get help with Moose
- **[ğŸ› Moose Issues](https://github.com/514-labs/moose/issues)** - Report Moose-related bugs
- **[ğŸ“š Moose Documentation](https://docs.fiveonefour.com/moose)** - Comprehensive guides

### ğŸ—ï¸ **Area Code Demo Support**

For issues and questions about this demo:

1. Check the troubleshooting section above
2. Open an issue on GitHub with your machine configuration
3. Join our development discussions for alpha testing feedback

## ğŸ¦Œ **Built with Moose**

This repository demonstrates Moose's capabilities for building production-ready operational data warehouses with:

- **Real-time analytics** with ClickHouse
- **Event streaming** with Redpanda
- **Reliable workflows** with Temporal
- **Interactive dashboards** with Streamlit

**[ğŸš€ Get Started with Moose](https://github.com/514-labs/moose)** | **[ğŸ“š Moose Documentation](https://docs.fiveonefour.com/moose)**
